{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mFailed to resolve env \"C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\python.exe\". \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import json \n",
    "from PIL import Image\n",
    "from random import randint\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataloader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first 3D image:  (882, 512, 512)\n",
      "Shape of the first 3D mask (882, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                                                                ####################################################\n",
    "                                                                ######## Reading data from my local PC #############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "masks_path = Path(r'/storage/brno2/home/yauheni/unetr3D/masks_for_all_organs')\n",
    "data_path = Path(r'/storage/brno2/home/yauheni/workspase')\n",
    "\n",
    "sorted_pictures = sorted(\n",
    "        [d.name for d in data_path.iterdir() if d.is_dir() and d.name.isdigit()],\n",
    "        key=lambda x: int(x)\n",
    "    )\n",
    "\n",
    "sorted_masks = sorted(\n",
    "        [d.name for d in masks_path.iterdir() if d.is_dir() and d.name.isdigit()],\n",
    "        key=lambda x: int(x)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "images_3d_full = []\n",
    "for image_3d in sorted_pictures:\n",
    "    images_path = Path(fr'/storage/brno2/home/yauheni/workspase/{image_3d}/data')\n",
    "    images = []\n",
    "    for image in images_path.iterdir():\n",
    "        img = Image.open(image)\n",
    "        img = img.convert('L')\n",
    "        img = np.array(img)\n",
    "        images.append(img)\n",
    "    images_3d_full.append(np.array(images))\n",
    "print(\"Shape of the first 3D image: \", images_3d_full[0].shape)\n",
    "\n",
    "masks_3d_full = []\n",
    "for mask_3d in sorted_masks:\n",
    "    masks_path = Path(fr'/storage/brno2/home/yauheni/unetr3D/masks_for_all_organs/{mask_3d}')\n",
    "    masks = []\n",
    "    for mask in masks_path.iterdir():\n",
    "        img = Image.open(mask)\n",
    "        img = np.array(img)\n",
    "        masks.append(img)\n",
    "    masks_3d_full.append(np.array(masks))\n",
    "print(\"Shape of the first 3D mask\", masks_3d_full[0].shape)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape for changed mask:  (8, 272, 512, 512)\n",
      "Shape for cutted image:  (272, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "                                                                ########################################################\n",
    "                                                                #Processing data from ny local PC and using dataloaders#\n",
    "\n",
    "\n",
    "class DataTrain(Dataset):\n",
    "\n",
    "    def __init__(self, data, annotation):\n",
    "        self.traininputtensor = torch.tensor(data, dtype=torch.float).unsqueeze(0)\n",
    "        self.output = torch.tensor(annotation, dtype=torch.float)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_image = self.traininputtensor[index] \n",
    "        output_label = self.output[index]  \n",
    "        return input_image, output_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.traininputtensor.size(0)\n",
    "\n",
    "\n",
    "class DataTest(Dataset):\n",
    "\n",
    "    def __init__(self, data, annotation):\n",
    "        self.testinputtensor = torch.tensor(data, dtype=torch.float).unsqueeze(0)\n",
    "        self.output = torch.tensor(annotation, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_image = self.testinputtensor[index]\n",
    "        output_label = self.output[index] \n",
    "        return input_image, output_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.testinputtensor.size(0)\n",
    "\n",
    "\n",
    "def reshape_mask(mask, num_clases=8, depth=272):\n",
    "    \"\"\"We wanted to convert our 3d masks that have shape (1,D,H,W) to the shape (num_classes,D,H,W) \"\"\"\n",
    "    new_mask = np.zeros((num_clases, depth, 512, 512), dtype=np.uint8)\n",
    "\n",
    "    for z in range(depth):  #iteration over 'z' axis \n",
    "        for y in range(512):    #iteration over 'y' axis\n",
    "            for x in range(512):    #iteration over 'x' axis\n",
    "                value = mask[z, x, y]\n",
    "                trida = value/25\n",
    "                if trida==10:\n",
    "                    trida=8\n",
    "                new_mask[trida, z, x, y] = 1\n",
    "\n",
    "    return new_mask\n",
    "\n",
    "\n",
    "\n",
    "def cut_data(data, z_shape=272):\n",
    "    \"\"\"Metacentrum haven't got enough memory to process one full image, that's why it will be cutted \"\"\"\n",
    "    cutted_data = []\n",
    "\n",
    "    for i in range(0, data.shape[0], z_shape):\n",
    "        new_data = np.array(data[i:i+z_shape, :, :])\n",
    "        cutted_data.append(new_data)\n",
    "\n",
    "    #for neural network we must have same dimension\n",
    "    if cutted_data[-1].shape[0] < z_shape:\n",
    "        cutted_data.pop(-1)\n",
    "\n",
    "    return cutted_data\n",
    "\n",
    "\n",
    "#experement with one 3d picture\n",
    "one_3d_picture = images_3d_full[0]\n",
    "one_3d_mask = masks_3d_full[0]\n",
    "\n",
    "cutted_picture = cut_data(one_3d_picture)\n",
    "cutted_mask = cut_data(one_3d_mask)\n",
    "\n",
    "reshaped_mask = reshape_mask(cutted_mask[0])\n",
    "print(\"Shape for changed mask: \", reshaped_mask.shape)\n",
    "print(\"Shape for cutted image: \", cutted_picture[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\monai\\utils\\deprecate_utils.py:221: FutureWarning: monai.networks.nets.unetr UNETR.__init__:pos_embed: Argument `pos_embed` has been deprecated since version 1.2. It will be removed in version 1.4. please use `proj_type` instead.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' modelwise.load_state_dict(torch.load(os.path.join(r\"/storage/brno2/home/yauheni\", \"best_metric_model.pth\")))\\nmodel_state_dict1 = modelwise.state_dict()\\nfor name_dst, param_dst in model.named_parameters():\\n    if name_dst in modelwise.state_dict():\\n        param_src = model.state_dict()[name_dst]\\n        if param_src.size() == param_dst.size():\\n            param_dst.data.copy_(param_src.data)\\n        else:\\n            print(f\"Skipping layer {name_dst} due to size mismatch\") '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = get_default_device()\n",
    "\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=8,\n",
    "    img_size=(272, 512, 512),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "modelwise = UNETR(   #just_to_copy_weights\n",
    "    in_channels=1,\n",
    "    out_channels=14,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "modelwise.load_state_dict(torch.load(os.path.join(r\"/storage/brno2/home/yauheni\", \"best_metric_model.pth\")))\n",
    "model_state_dict1 = modelwise.state_dict()\n",
    "for name_dst, param_dst in model.named_parameters():\n",
    "    if name_dst in modelwise.state_dict():\n",
    "        param_src = model.state_dict()[name_dst]\n",
    "        if param_src.size() == param_dst.size():\n",
    "            param_dst.data.copy_(param_src.data)\n",
    "        else:\n",
    "            print(f\"Skipping layer {name_dst} due to size mismatch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data: (1, 272, 512, 512)\n",
      "Shape of annotation: (1, 8, 272, 512, 512)\n",
      "Input image shape:  torch.Size([1, 272, 512, 512])\n",
      "Output image shape:  torch.Size([8, 272, 512, 512])\n",
      "Shape of image:  torch.Size([1, 1, 272, 512, 512])\n",
      "Shape of mask:  torch.Size([1, 8, 272, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "data_train = DataTrain(np.array([cutted_picture[0]]), np.array([reshaped_mask]))\n",
    "dataloader_train = DataLoader(dataset=data_train, batch_size=1, shuffle=True)\n",
    "for data in dataloader_train:\n",
    "    image, mask = data\n",
    "    print(\"Shape of image: \", image.shape)\n",
    "    print(\"Shape of mask: \", mask.shape)\n",
    "    out = modelwise(image)\n",
    "    print(\"Shape of the mask: \", mask.shape)\n",
    "    print(\"Shape of the output: \", out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 96, 96, 96])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(1, 1, 96, 96, 96) #now we know shape of tensor we want \n",
    "out = modelwise(tensor)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                ###############################################################\n",
    "                                                #######################training_loop###########################\n",
    "\n",
    "#train must include vena_cava ,portal_vien and liver images such data are included in 5 and 14 pictures\n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "\n",
    "cutted_5 = cut_data(images_3d_full[4])\n",
    "cutted_14 = cut_data(images_3d_full[13])\n",
    "\n",
    "cutted_mask_5 = cut_data(masks_3d_full[4])\n",
    "cutted_mask_14 = cut_data(masks_3d_full[13])\n",
    "\n",
    "for i in range(len(cutted_5)):\n",
    "    trainX.append(cutted_5[i])\n",
    "    trainY.append(reshape_mask(cutted_mask_5[i]))\n",
    "\n",
    "for i in range(len(cutted_14)):\n",
    "    trainX.append(cutted_14[i])\n",
    "    trainY.append(reshape_mask(cutted_mask_14[i]))\n",
    "\n",
    "\n",
    "X_for_mix = []\n",
    "Y_for_mix = []\n",
    "for i in range(len(images_3d_full)):\n",
    "\n",
    "    if i != 4 and i != 13:\n",
    "\n",
    "        cutted = cut_data(images_3d_full[i])\n",
    "        cutted_mask = cut_data(masks_3d_full[i])\n",
    "\n",
    "        X_for_mix.extend(cutted)\n",
    "        Y_for_mix.extend(cutted_mask)\n",
    "\n",
    "\n",
    "res_train_x, testX, res_train_y, testY = train_test_split(X_for_mix, Y_for_mix, test_size=0.33)\n",
    "trainX.extend(res_train_x)\n",
    "trainY.extend(res_train_y)\n",
    "\n",
    "\n",
    "\n",
    "root_dir = r'/storage/brno2/home/yauheni/unetr3D'\n",
    "\n",
    "data_train = DataTrain(np.array(trainX), np.array(trainY))\n",
    "dataloader_train = DataLoader(dataset=data_train, batch_size=1, shuffle=True)\n",
    "\n",
    "data_test = DataTrain(np.array(testX), np.array(testY))\n",
    "dataloader_test = DataLoader(dataset=data_test, batch_size=1, shuffle=True)\n",
    "\n",
    "dice_metric_with_bg = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "\n",
    "\n",
    "loss_fn =  DiceCELoss(to_onehot_y=True, sigmoid=True)\n",
    "lr = 1e-4\n",
    "num_epochs = 2500\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimazer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "history = []\n",
    "history1 = []\n",
    "acc_val = []\n",
    "acc_test = []\n",
    "acc_train = []\n",
    "dice_metric_best = 0\n",
    "number_of_epoch_best = 0\n",
    "for epochs in range(num_epochs):\n",
    "    with tqdm(total=17, desc=f'Epoch {epochs + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        running_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        for i, data in enumerate(dataloader_train):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimazer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, labels)\n",
    "            loss.backward()\n",
    "            optimazer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "            preds = (labels>0.5).float()\n",
    "            output = (output>0.5).float()\n",
    "            dice_metric_with_bg(y_pred=output, y=preds)\n",
    "            dice_score = dice_metric_with_bg.aggregate().item()\n",
    "            acc_train.append(dice_score)\n",
    "            dice_metric_with_bg.reset()\n",
    "            pbar.update(1)\n",
    "        history.append(running_loss)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for j, data in enumerate(dataloader_test):\n",
    "        with torch.no_grad():\n",
    "            inputs_for_test, labels_for_test = data\n",
    "            inputs_for_test = inputs_for_test.to(device)\n",
    "            labels_for_test = labels_for_test.to(device)\n",
    "            output_for_test = model(inputs_for_test)\n",
    "            preds = (labels_for_test>0.5).float()\n",
    "            output = (output_for_test>0.5).float()\n",
    "            dice_metric_with_bg(y_pred=output, y=preds)\n",
    "    dice_score = dice_metric_with_bg.aggregate().item()\n",
    "    acc_val.append(dice_score)\n",
    "    if dice_score>dice_metric_best:\n",
    "        number_of_epoch_best = epochs\n",
    "        dice_metric_best = dice_score\n",
    "        torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model_pigs.pth\"))\n",
    "        print(\n",
    "                \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(dice_metric_best, dice_score)\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "                \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_metric_best, dice_score\n",
    "                    )\n",
    "                )\n",
    "        dice_metric_with_bg.reset()\n",
    "print(\"Train history\", history)\n",
    "print(\"Accuracy train\", acc_train)\n",
    "print(\"Accuracy validation\", acc_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path = r'/storage/brno2/home/yauheni/unetr3D/history_pigs.pkl'\n",
    "\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(history, file)\n",
    "    print(f\"File created and data saved: {file_path}\")\n",
    "else:\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(history, file)\n",
    "    print(f\"Data saved to existing file: {file_path}\")\n",
    "\n",
    "\n",
    "file_path = r'/storage/brno2/home/yauheni/unetr3D/acc_train_pigs.pkl'\n",
    "\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(acc_train, file)\n",
    "    print(f\"File created and data saved: {file_path}\")\n",
    "else:\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(acc_train, file)\n",
    "    print(f\"Data saved to existing file: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "file_path = r'/storage/brno2/home/yauheni/unetr3D/acc_val.pkl'\n",
    "\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(acc_val, file)\n",
    "    print(f\"File created and data saved: {file_path}\")\n",
    "else:\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(acc_val, file)\n",
    "    print(f\"Data saved to existing file: {file_path}\")\n",
    "\n",
    "print(\"The end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
